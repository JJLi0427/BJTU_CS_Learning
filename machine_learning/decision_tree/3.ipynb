{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实现决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实验内容：  \n",
    "使用LendingClub Safe Loans数据集：\n",
    "1. 实现信息增益、信息增益率、基尼指数三种划分标准\n",
    "2. 使用给定的训练集完成三种决策树的训练过程\n",
    "3. 计算三种决策树在最大深度为6时测试集上的精度，查准率，查全率，F1值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这部分，我们会实现一个很简单的二叉决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入类库\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入数据\n",
    "loans = pd.read_csv('data/lendingclub/lending-club-data.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对数据进行预处理，将safe_loans作为标记\n",
    "loans['safe_loans'] = loans['bad_loans'].apply(lambda x : +1 if x==0 else -1)\n",
    "del loans['bad_loans']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们只使用grade, term, home_ownership, emp_length这四列作为特征，safe_loans作为标记，只保留loans中的这五列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['grade', 'term','home_ownership','emp_length']\n",
    "target = 'safe_loans'\n",
    "loans = loans[features + [target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 划分训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "loans = shuffle(loans, random_state = 34)\n",
    "split_line = int(len(loans) * 0.6)\n",
    "train_data = loans.iloc[: split_line]\n",
    "test_data = loans.iloc[split_line:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 特征预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(data, features_categorical):\n",
    "    for cat in features_categorical:\n",
    "        one_encoding = pd.get_dummies(data[cat], prefix = cat)\n",
    "        data = pd.concat([data, one_encoding],axis=1)\n",
    "        del data[cat]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = one_hot_encoding(train_data, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取所有特征的名字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grade_A',\n",
       " 'grade_B',\n",
       " 'grade_C',\n",
       " 'grade_D',\n",
       " 'grade_E',\n",
       " 'grade_F',\n",
       " 'grade_G',\n",
       " 'term_ 36 months',\n",
       " 'term_ 60 months',\n",
       " 'home_ownership_MORTGAGE',\n",
       " 'home_ownership_OTHER',\n",
       " 'home_ownership_OWN',\n",
       " 'home_ownership_RENT',\n",
       " 'emp_length_1 year',\n",
       " 'emp_length_10+ years',\n",
       " 'emp_length_2 years',\n",
       " 'emp_length_3 years',\n",
       " 'emp_length_4 years',\n",
       " 'emp_length_5 years',\n",
       " 'emp_length_6 years',\n",
       " 'emp_length_7 years',\n",
       " 'emp_length_8 years',\n",
       " 'emp_length_9 years',\n",
       " 'emp_length_< 1 year']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_features = train_data.columns.tolist()\n",
    "one_hot_features.remove(target)\n",
    "one_hot_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来是对测试集进行one_hot编码，但只要保留出现在one_hot_features中的特征即可·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_tmp = one_hot_encoding(test_data, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个空的DataFrame\n",
    "test_data = pd.DataFrame(columns = train_data.columns)\n",
    "for feature in train_data.columns:\n",
    "    # 如果训练集中当前特征在test_data_tmp中出现了，将其复制到test_data中\n",
    "    if feature in test_data_tmp.columns:\n",
    "        test_data[feature] = test_data_tmp[feature].copy()\n",
    "    else:\n",
    "        # 否则就用全为0的列去替代\n",
    "        test_data[feature] = np.zeros(test_data_tmp.shape[0], dtype = 'uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>safe_loans</th>\n",
       "      <th>grade_A</th>\n",
       "      <th>grade_B</th>\n",
       "      <th>grade_C</th>\n",
       "      <th>grade_D</th>\n",
       "      <th>grade_E</th>\n",
       "      <th>grade_F</th>\n",
       "      <th>grade_G</th>\n",
       "      <th>term_ 36 months</th>\n",
       "      <th>term_ 60 months</th>\n",
       "      <th>...</th>\n",
       "      <th>emp_length_10+ years</th>\n",
       "      <th>emp_length_2 years</th>\n",
       "      <th>emp_length_3 years</th>\n",
       "      <th>emp_length_4 years</th>\n",
       "      <th>emp_length_5 years</th>\n",
       "      <th>emp_length_6 years</th>\n",
       "      <th>emp_length_7 years</th>\n",
       "      <th>emp_length_8 years</th>\n",
       "      <th>emp_length_9 years</th>\n",
       "      <th>emp_length_&lt; 1 year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37225</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101585</th>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31865</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97692</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88181</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        safe_loans  grade_A  grade_B  grade_C  grade_D  grade_E  grade_F  \\\n",
       "37225            1    False    False    False    False     True    False   \n",
       "101585          -1    False     True    False    False    False    False   \n",
       "31865            1     True    False    False    False    False    False   \n",
       "97692            1    False    False     True    False    False    False   \n",
       "88181            1     True    False    False    False    False    False   \n",
       "\n",
       "        grade_G  term_ 36 months  term_ 60 months  ...  emp_length_10+ years  \\\n",
       "37225     False             True            False  ...                 False   \n",
       "101585    False             True            False  ...                 False   \n",
       "31865     False             True            False  ...                 False   \n",
       "97692     False             True            False  ...                  True   \n",
       "88181     False             True            False  ...                 False   \n",
       "\n",
       "        emp_length_2 years  emp_length_3 years  emp_length_4 years  \\\n",
       "37225                 True               False               False   \n",
       "101585               False               False                True   \n",
       "31865                False               False               False   \n",
       "97692                False               False               False   \n",
       "88181                False               False               False   \n",
       "\n",
       "        emp_length_5 years  emp_length_6 years  emp_length_7 years  \\\n",
       "37225                False               False               False   \n",
       "101585               False               False               False   \n",
       "31865                False               False               False   \n",
       "97692                False               False               False   \n",
       "88181                False                True               False   \n",
       "\n",
       "        emp_length_8 years  emp_length_9 years  emp_length_< 1 year  \n",
       "37225                False               False                False  \n",
       "101585               False               False                False  \n",
       "31865                False               False                False  \n",
       "97692                False               False                False  \n",
       "88181                False               False                False  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73564, 25)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49043, 25)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**处理完后，所有的特征都是0和1，标记是1和-1**，以上就是数据预处理流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 实现3种特征划分准则"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树中有很多常用的特征划分方法，比如信息增益、信息增益率、基尼指数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们需要实现一个函数，它的作用是，给定决策树的某个结点内的所有样本的标记，让它计算出对应划分指标的值是多少"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们会实现上述三种划分指标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**这里我们约定，将所有特征取值为0的样本，划分到左子树，特征取值为1的样本，划分到右子树**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 信息增益"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_entropy(labels_in_node):\n",
    "    '''\n",
    "    求当前结点的信息熵\n",
    "    '''\n",
    "    # 统计样本总个数\n",
    "    num_of_samples = labels_in_node.shape[0]\n",
    "    \n",
    "    if num_of_samples == 0:\n",
    "        return 0\n",
    "    # 统计出标记为1的个数\n",
    "    num_of_positive = len(labels_in_node[labels_in_node == 1])\n",
    "    # 统计出标记为-1的个数\n",
    "    num_of_negative = len(labels_in_node[labels_in_node == -1])             # YOUR CODE HERE\n",
    "    # 统计正例的概率\n",
    "    prob_positive = num_of_positive / num_of_samples\n",
    "    # 统计负例的概率\n",
    "    prob_negative = num_of_negative / num_of_samples                 # YOUR CODE HERE\n",
    "    if prob_positive == 0:\n",
    "        positive_part = 0\n",
    "    else:\n",
    "        positive_part = prob_positive * np.log2(prob_positive)\n",
    "    \n",
    "    if prob_negative == 0:\n",
    "        negative_part = 0\n",
    "    else:\n",
    "        negative_part = prob_negative * np.log2(prob_negative)\n",
    "    \n",
    "    return - ( positive_part + negative_part )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_information_gains(data, features, target, annotate = False):\n",
    "    '''\n",
    "    计算所有特征的信息增益\n",
    "    '''\n",
    "    information_gains = dict()\n",
    "    for feature in features:\n",
    "        left_split_target = data[data[feature] == 0][target]\n",
    "        right_split_target =  data[data[feature] == 1][target]\n",
    "        left_entropy = information_entropy(left_split_target)\n",
    "        left_weight = len(left_split_target) / (len(left_split_target) + len(right_split_target))\n",
    "\n",
    "        # 计算右子树的信息熵\n",
    "        right_entropy = information_entropy(right_split_target)                         # YOUR CODE HERE\n",
    "        # 计算右子树的权重\n",
    "        right_weight = len(right_split_target) / (len(left_split_target) + len(right_split_target))                          # YOUR CODE HERE\n",
    "        # 计算当前结点的信息熵\n",
    "        current_entropy = information_entropy(data[target])\n",
    "        # 计算使用当前特征划分的信息增益\n",
    "        gain = current_entropy - (left_weight * left_entropy + right_weight * right_entropy)                                  # YOUR CODE HERE\n",
    "        # 将特征名与增益值以键值对的形式存储在information_gains中\n",
    "        information_gains[feature] = gain\n",
    "        if annotate:\n",
    "            print(\" \", feature, gain)\n",
    "    return information_gains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 信息增益率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_information_gain_ratios(data, features, target, annotate = False):\n",
    "    '''\n",
    "    计算所有特征的信息增益率并保存起来\n",
    "    '''\n",
    "    gain_ratios = dict()\n",
    "    for feature in features:\n",
    "        left_split_target = data[data[feature] == 0][target]\n",
    "        right_split_target =  data[data[feature] == 1][target]\n",
    "        left_entropy = information_entropy(left_split_target)\n",
    "        \n",
    "        # 计算左子树的权重\n",
    "        left_weight = len(left_split_target) / (len(left_split_target) + len(right_split_target))\n",
    "        # 计算右子树的信息熵\n",
    "        right_entropy = information_entropy(right_split_target)                             # YOUR CODE HERE\n",
    "        # 计算右子树的权重\n",
    "        right_weight = len(right_split_target) / (len(left_split_target) + len(right_split_target))                              # YOUR CODE HERE\n",
    "        # 计算当前结点的信息熵\n",
    "        current_entropy = information_entropy(data[target])\n",
    "        # 计算当前结点的信息增益\n",
    "        gain = current_entropy - (left_weight * left_entropy + right_weight * right_entropy)                                       # YOUR CODE HERE\n",
    "        \n",
    "        if left_weight == 0:\n",
    "            left_IV = 0\n",
    "        else:\n",
    "            left_IV = left_weight * np.log2(left_weight)\n",
    "        \n",
    "        # 计算IV公式中，当前特征为1的值\n",
    "        if right_weight == 0:\n",
    "            right_IV = 0\n",
    "        else:\n",
    "            right_IV = right_weight * np.log2(right_weight)                              # YOUR CODE HERE\n",
    "\n",
    "        IV = - (left_IV + right_IV)\n",
    "        gain_ratio = gain / (IV + np.finfo(np.longdouble).eps)\n",
    "        gain_ratios[feature] = gain_ratio\n",
    "        if annotate:\n",
    "            print(\" \", feature, gain_ratio)\n",
    "            \n",
    "    return gain_ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 基尼指数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(labels_in_node):\n",
    "    '''\n",
    "    计算一个结点内样本的基尼指数\n",
    "    '''\n",
    "    num_of_samples = labels_in_node.shape[0]\n",
    "    if num_of_samples == 0:\n",
    "        return 0\n",
    "    num_of_positive = len(labels_in_node[labels_in_node == 1])\n",
    "    # 统计出-1的个数\n",
    "    num_of_negative = len(labels_in_node[labels_in_node == -1])                    # YOUR CODE HERE\n",
    "    # 统计正例的概率\n",
    "    prob_positive = num_of_positive / num_of_samples\n",
    "    # 统计负例的概率\n",
    "    prob_negative = num_of_negative / num_of_samples                       # YOUR CODE HERE\n",
    "    # 计算基尼值\n",
    "    gini = 1 - prob_positive**2 - prob_negative**2                                # YOUR CODE HERE\n",
    "    \n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gini_indices(data, features, target, annotate = False):\n",
    "    '''\n",
    "    计算使用各个特征进行划分时，各特征的基尼指数\n",
    "    '''\n",
    "    \n",
    "    gini_indices = dict()\n",
    "    for feature in features:\n",
    "        left_split_target = data[data[feature] == 0][target]\n",
    "        right_split_target =  data[data[feature] == 1][target]\n",
    "        left_gini = gini(left_split_target)\n",
    "        \n",
    "        # 计算左子树的权重\n",
    "        left_weight = len(left_split_target) / (len(left_split_target) + len(right_split_target))\n",
    "        # 计算右子树的基尼值\n",
    "        right_gini = gini(right_split_target)                                  # YOUR CODE HERE\n",
    "        # 计算右子树的权重\n",
    "        right_weight = len(right_split_target) / (len(left_split_target) + len(right_split_target))                                # YOUR CODE HERE\n",
    "        # 计算当前结点的基尼指数\n",
    "        gini_index = left_weight * left_gini + right_weight * right_gini                                  # YOUR CODE HERE\n",
    "\n",
    "        gini_indices[feature] = gini_index\n",
    "        \n",
    "        if annotate:\n",
    "            print(\" \", feature, gini_index)\n",
    "            \n",
    "    return gini_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 完成最优特征的选择 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_splitting_feature(data, features, target, criterion = 'gini', annotate = False):\n",
    "    '''\n",
    "    给定划分方法和数据，找到最优的划分特征\n",
    "    \n",
    "    '''\n",
    "    if criterion == 'information_gain':\n",
    "        if annotate:\n",
    "            print('using information gain')\n",
    "        information_gains = compute_information_gains(data, features, target, annotate)\n",
    "        best_feature = max(information_gains.items(), key = lambda x: x[1])[0]\n",
    "        return best_feature\n",
    "\n",
    "    elif criterion == 'gain_ratio':\n",
    "        if annotate:\n",
    "            print('using information gain ratio')\n",
    "        gain_ratios = compute_information_gain_ratios(data, features, target, annotate)\n",
    "        # 根据这些特征和他们的信息增益率，找到最佳的划分特征\n",
    "        best_feature = max(gain_ratios.items(), key=lambda item: item[1])[0]                                                   # YOUR CODE HERE\n",
    "        return best_feature\n",
    "    \n",
    "    elif criterion == 'gini':\n",
    "        if annotate:\n",
    "            print('using gini')\n",
    "        gini_indices = compute_gini_indices(data, features, target, annotate)\n",
    "        # 根据这些特征和他们的基尼指数，找到最佳的划分特征\n",
    "        best_feature = min(gini_indices.items(), key=lambda item: item[1])[0]                                                   # YOUR CODE HERE\n",
    "        return best_feature\n",
    "    else:\n",
    "        raise Exception(\"传入的criterion不合规!\", criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 判断结点内样本的类别是否为同一类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intermediate_node_num_mistakes(labels_in_node):\n",
    "    '''\n",
    "    求树的结点中，样本数少的那个类的样本有多少，比如输入是[1, 1, -1, -1, 1]，返回2\n",
    "    \n",
    "    '''\n",
    "    if len(labels_in_node) == 0:\n",
    "        return 0\n",
    "    # 统计1的个数\n",
    "    num_of_one = len(labels_in_node[labels_in_node == 1])                                    # YOUR CODE HERE\n",
    "    # 统计-1的个数\n",
    "    num_of_minus_one = len(labels_in_node[labels_in_node == -1])                              # YOUR CODE HERE\n",
    "    return num_of_one if num_of_minus_one > num_of_one else num_of_minus_one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 创建叶子结点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_leaf(target_values):\n",
    "    '''\n",
    "    计算出当前叶子结点的标记是什么，并且将叶子结点信息保存在一个dict中\n",
    "    '''\n",
    "    # 创建叶子结点\n",
    "    leaf = {'splitting_feature' : None,'left' : None,'right' : None,'is_leaf': True}\n",
    "    num_ones = len(target_values[target_values == +1])\n",
    "    num_minus_ones = len(target_values[target_values == -1])\n",
    "    if num_ones > num_minus_ones:\n",
    "        leaf['prediction'] = 1\n",
    "    else:\n",
    "        leaf['prediction'] = -1\n",
    "    return leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 递归地创建决策树\n",
    "递归的创建决策树  \n",
    "递归算法终止的三个条件：\n",
    "1. 如果结点内所有的样本的标记都相同，该结点就不需要再继续划分，直接做叶子结点即可\n",
    "2. 如果结点所有的特征都已经在之前使用过了，在当前结点无剩余特征可供划分样本，该结点直接做叶子结点\n",
    "3. 如果当前结点的深度已经达到了我们限制的树的最大深度，直接做叶子结点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**这里需要填写五个部分**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_create(data, features, target, criterion = 'gini', current_depth = 0, max_depth = 10, annotate = False):\n",
    "    if criterion not in ['information_gain', 'gain_ratio', 'gini']:\n",
    "        raise Exception(\"传入的criterion不合规!\", criterion)\n",
    "    remaining_features = features[:]\n",
    "    target_values = data[target]\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Subtree, depth = %s (%s data points).\" % (current_depth, len(target_values)))\n",
    "    if intermediate_node_num_mistakes(target_values) == 0: \n",
    "        print(\"Stopping condition 1 reached.\")\n",
    "        return create_leaf(target_values)\n",
    "    # 如果已经没有剩余的特征可供分割，即remaining_features为空\n",
    "    if len(remaining_features) == 0:                                                                  # YOUR CODE HERE\n",
    "        print(\"Stopping condition 2 reached.\")\n",
    "        return create_leaf(target_values)\n",
    "    # 如果已经到达了我们要求的最大深度，即当前深度达到了最大深度\n",
    "    if current_depth >= max_depth:                                                                 # YOUR CODE HERE\n",
    "        print(\"Reached maximum depth. Stopping for now.\")\n",
    "        return create_leaf(target_values)\n",
    "    splitting_feature = best_splitting_feature(data,features,target,criterion)\n",
    "    # 左子树的数据\n",
    "    left_split = data[data[splitting_feature] == 0]\n",
    "    # 右子树的数据\n",
    "    right_split = data[data[splitting_feature] == 1]                                                    # YOUR CODE HERE\n",
    "    \n",
    "    remaining_features.remove(splitting_feature)\n",
    "    print(\"Split on feature %s. (%s, %s)\" % (\\\n",
    "                      splitting_feature, len(left_split), len(right_split)))\n",
    "    if len(left_split) == len(data):\n",
    "        print(\"Creating leaf node.\")\n",
    "        return create_leaf(left_split[target])\n",
    "    \n",
    "    # 判断右子树是不是“完美”的\n",
    "    if len(right_split) == len(data):\n",
    "        print(\"Creating right node.\")\n",
    "        return create_leaf(right_split[target])                                                      # YOUR CODE HERE\n",
    "\n",
    "    left_tree = decision_tree_create(left_split, remaining_features, target, criterion, current_depth + 1, max_depth, annotate)\n",
    "    right_tree = decision_tree_create(right_split, remaining_features, target, criterion, current_depth + 1, max_depth, annotate)                                                   # YOUR CODE HERE\n",
    "    return {'is_leaf': False,'prediction': None,'splitting_feature': splitting_feature,'left': left_tree,'right': right_tree}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练一个模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Subtree, depth = 0 (73564 data points).\n",
      "Split on feature term_ 36 months. (14831, 58733)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 1 (14831 data points).\n",
      "Split on feature grade_F. (13003, 1828)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 2 (13003 data points).\n",
      "Split on feature grade_E. (9818, 3185)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 3 (9818 data points).\n",
      "Split on feature home_ownership_RENT. (6796, 3022)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (6796 data points).\n",
      "Split on feature grade_G. (6507, 289)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (6507 data points).\n",
      "Split on feature grade_D. (4368, 2139)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (4368 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (2139 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (289 data points).\n",
      "Split on feature home_ownership_OWN. (249, 40)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (249 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (40 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (3022 data points).\n",
      "Split on feature grade_G. (2827, 195)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (2827 data points).\n",
      "Split on feature grade_D. (1651, 1176)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (1651 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (1176 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (195 data points).\n",
      "Split on feature emp_length_2 years. (176, 19)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (176 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (19 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 3 (3185 data points).\n",
      "Split on feature home_ownership_RENT. (1980, 1205)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (1980 data points).\n",
      "Split on feature emp_length_3 years. (1828, 152)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (1828 data points).\n",
      "Split on feature emp_length_10+ years. (1057, 771)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (1057 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (771 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (152 data points).\n",
      "Split on feature home_ownership_OTHER. (151, 1)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (151 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (1 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (1205 data points).\n",
      "Split on feature emp_length_1 year. (1124, 81)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (1124 data points).\n",
      "Split on feature emp_length_8 years. (1073, 51)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (1073 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (51 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (81 data points).\n",
      "Split on feature grade_A. (81, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 2 (1828 data points).\n",
      "Split on feature home_ownership_RENT. (1030, 798)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 3 (1030 data points).\n",
      "Split on feature emp_length_3 years. (957, 73)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (957 data points).\n",
      "Split on feature emp_length_2 years. (886, 71)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (886 data points).\n",
      "Split on feature home_ownership_OTHER. (884, 2)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (884 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (2 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (71 data points).\n",
      "Split on feature home_ownership_MORTGAGE. (12, 59)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (12 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (59 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (73 data points).\n",
      "Split on feature home_ownership_MORTGAGE. (13, 60)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (13 data points).\n",
      "Split on feature grade_A. (13, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (60 data points).\n",
      "Split on feature grade_A. (60, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 3 (798 data points).\n",
      "Split on feature emp_length_7 years. (740, 58)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (740 data points).\n",
      "Split on feature emp_length_3 years. (673, 67)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (673 data points).\n",
      "Split on feature emp_length_9 years. (646, 27)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (646 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (27 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (67 data points).\n",
      "Split on feature grade_A. (67, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (58 data points).\n",
      "Split on feature grade_A. (58, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 1 (58733 data points).\n",
      "Split on feature grade_A. (45632, 13101)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 2 (45632 data points).\n",
      "Split on feature grade_B. (25130, 20502)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 3 (25130 data points).\n",
      "Split on feature grade_C. (11066, 14064)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (11066 data points).\n",
      "Split on feature home_ownership_MORTGAGE. (6987, 4079)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (6987 data points).\n",
      "Split on feature grade_F. (6650, 337)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (6650 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (337 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (4079 data points).\n",
      "Split on feature grade_G. (4003, 76)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (4003 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (76 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (14064 data points).\n",
      "Split on feature home_ownership_MORTGAGE. (8209, 5855)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (8209 data points).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on feature emp_length_2 years. (7209, 1000)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (7209 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (1000 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (5855 data points).\n",
      "Split on feature emp_length_10+ years. (3802, 2053)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (3802 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (2053 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 3 (20502 data points).\n",
      "Split on feature home_ownership_MORTGAGE. (10775, 9727)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (10775 data points).\n",
      "Split on feature home_ownership_OTHER. (10741, 34)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (10741 data points).\n",
      "Split on feature emp_length_1 year. (9754, 987)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (9754 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (987 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (34 data points).\n",
      "Split on feature emp_length_10+ years. (27, 7)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (27 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (7 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (9727 data points).\n",
      "Split on feature emp_length_< 1 year. (9186, 541)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (9186 data points).\n",
      "Split on feature emp_length_9 years. (8807, 379)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (8807 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (379 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (541 data points).\n",
      "Split on feature grade_C. (541, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 2 (13101 data points).\n",
      "Split on feature home_ownership_MORTGAGE. (5830, 7271)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 3 (5830 data points).\n",
      "Split on feature emp_length_3 years. (5283, 547)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (5283 data points).\n",
      "Split on feature emp_length_1 year. (4705, 578)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (4705 data points).\n",
      "Split on feature emp_length_7 years. (4467, 238)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (4467 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (238 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (578 data points).\n",
      "Split on feature home_ownership_OTHER. (576, 2)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (576 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (2 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (547 data points).\n",
      "Split on feature home_ownership_OTHER. (545, 2)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (545 data points).\n",
      "Split on feature home_ownership_OWN. (468, 77)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (468 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (77 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (2 data points).\n",
      "Split on feature grade_B. (2, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 3 (7271 data points).\n",
      "Split on feature emp_length_2 years. (6702, 569)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (6702 data points).\n",
      "Split on feature emp_length_4 years. (6234, 468)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (6234 data points).\n",
      "Split on feature emp_length_3 years. (5689, 545)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (5689 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (545 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (468 data points).\n",
      "Split on feature grade_B. (468, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (569 data points).\n",
      "Split on feature grade_B. (569, 0)\n",
      "Creating leaf node.\n"
     ]
    }
   ],
   "source": [
    "my_decision_tree = decision_tree_create(train_data, one_hot_features, target, 'gini', max_depth = 6, annotate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，模型就训练好了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们需要完成预测函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(tree, x, annotate = False):\n",
    "    '''\n",
    "    递归的进行预测，一次只能预测一个样本\n",
    "    '''\n",
    "    if tree['is_leaf']:\n",
    "        if annotate:\n",
    "            print (\"At leaf, predicting %s\" % tree['prediction'])\n",
    "        return tree['prediction']\n",
    "    else:\n",
    "        split_feature_value = x[tree['splitting_feature']]\n",
    "        if annotate:\n",
    "             print (\"Split on %s = %s\" % (tree['splitting_feature'], split_feature_value))\n",
    "        if split_feature_value == 0:\n",
    "            return classify(tree['left'], x, annotate)\n",
    "        else:\n",
    "            return classify(tree['right'], x, annotate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们取测试集第一个样本来测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "safe_loans                     1\n",
      "grade_A                    False\n",
      "grade_B                    False\n",
      "grade_C                    False\n",
      "grade_D                    False\n",
      "grade_E                     True\n",
      "grade_F                    False\n",
      "grade_G                    False\n",
      "term_ 36 months             True\n",
      "term_ 60 months            False\n",
      "home_ownership_MORTGAGE     True\n",
      "home_ownership_OTHER       False\n",
      "home_ownership_OWN         False\n",
      "home_ownership_RENT        False\n",
      "emp_length_1 year          False\n",
      "emp_length_10+ years       False\n",
      "emp_length_2 years          True\n",
      "emp_length_3 years         False\n",
      "emp_length_4 years         False\n",
      "emp_length_5 years         False\n",
      "emp_length_6 years         False\n",
      "emp_length_7 years         False\n",
      "emp_length_8 years         False\n",
      "emp_length_9 years         False\n",
      "emp_length_< 1 year        False\n",
      "Name: 37225, dtype: object\n"
     ]
    }
   ],
   "source": [
    "test_sample = test_data.iloc[0]\n",
    "print(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True class: 1 \n",
      "Predicted class: 1 \n"
     ]
    }
   ],
   "source": [
    "print('True class: %s ' % (test_sample['safe_loans']))\n",
    "print('Predicted class: %s ' % classify(my_decision_tree, test_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "打印出使用决策树判断的过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on term_ 36 months = True\n",
      "Split on grade_A = False\n",
      "Split on grade_B = False\n",
      "Split on grade_C = False\n",
      "Split on home_ownership_MORTGAGE = True\n",
      "Split on grade_G = False\n",
      "At leaf, predicting 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(my_decision_tree, test_sample, annotate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 在测试集上对我们的模型进行评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先来编写一个批量预测的函数，传入的是整个测试集那样的pd.DataFrame，这个函数返回一个np.ndarray，存储模型的预测结果  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tree, data):\n",
    "    '''\n",
    "    按行遍历data，对每个样本进行预测，将值存在prediction中，最后返回np.ndarray\n",
    "    '''\n",
    "    predictions = np.zeros(len(data))\n",
    "    for i in range(len(data)):\n",
    "        predictions[i] = classify(tree,data.iloc[i])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 请你计算使用不同评价指标得到模型的四项指标的值，填写在下方表格内\n",
    "**树的最大深度为6**  \n",
    "**这里需要填写一个部分**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Subtree, depth = 0 (73564 data points).\n",
      "Split on feature term_ 36 months. (14831, 58733)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 1 (14831 data points).\n",
      "Split on feature grade_F. (13003, 1828)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 2 (13003 data points).\n",
      "Split on feature grade_E. (9818, 3185)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 3 (9818 data points).\n",
      "Split on feature home_ownership_RENT. (6796, 3022)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (6796 data points).\n",
      "Split on feature grade_G. (6507, 289)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (6507 data points).\n",
      "Split on feature grade_D. (4368, 2139)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (4368 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (2139 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (289 data points).\n",
      "Split on feature home_ownership_OWN. (249, 40)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (249 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (40 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (3022 data points).\n",
      "Split on feature grade_G. (2827, 195)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (2827 data points).\n",
      "Split on feature grade_D. (1651, 1176)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (1651 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (1176 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (195 data points).\n",
      "Split on feature emp_length_2 years. (176, 19)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (176 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (19 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 3 (3185 data points).\n",
      "Split on feature home_ownership_RENT. (1980, 1205)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (1980 data points).\n",
      "Split on feature emp_length_3 years. (1828, 152)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (1828 data points).\n",
      "Split on feature emp_length_10+ years. (1057, 771)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (1057 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (771 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (152 data points).\n",
      "Split on feature home_ownership_OTHER. (151, 1)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (151 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (1 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (1205 data points).\n",
      "Split on feature emp_length_1 year. (1124, 81)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (1124 data points).\n",
      "Split on feature emp_length_8 years. (1073, 51)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (1073 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (51 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (81 data points).\n",
      "Split on feature grade_A. (81, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 2 (1828 data points).\n",
      "Split on feature home_ownership_RENT. (1030, 798)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 3 (1030 data points).\n",
      "Split on feature emp_length_3 years. (957, 73)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (957 data points).\n",
      "Split on feature emp_length_2 years. (886, 71)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (886 data points).\n",
      "Split on feature home_ownership_OTHER. (884, 2)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (884 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (2 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (71 data points).\n",
      "Split on feature home_ownership_MORTGAGE. (12, 59)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (12 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (59 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (73 data points).\n",
      "Split on feature home_ownership_MORTGAGE. (13, 60)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (13 data points).\n",
      "Split on feature grade_A. (13, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (60 data points).\n",
      "Split on feature grade_A. (60, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 3 (798 data points).\n",
      "Split on feature emp_length_7 years. (740, 58)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (740 data points).\n",
      "Split on feature emp_length_3 years. (673, 67)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (673 data points).\n",
      "Split on feature emp_length_9 years. (646, 27)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (646 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (27 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (67 data points).\n",
      "Split on feature grade_A. (67, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (58 data points).\n",
      "Split on feature grade_A. (58, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 1 (58733 data points).\n",
      "Split on feature grade_A. (45632, 13101)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 2 (45632 data points).\n",
      "Split on feature grade_B. (25130, 20502)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 3 (25130 data points).\n",
      "Split on feature grade_C. (11066, 14064)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (11066 data points).\n",
      "Split on feature home_ownership_MORTGAGE. (6987, 4079)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (6987 data points).\n",
      "Split on feature grade_F. (6650, 337)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (6650 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (337 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (4079 data points).\n",
      "Split on feature grade_G. (4003, 76)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (4003 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (76 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (14064 data points).\n",
      "Split on feature home_ownership_MORTGAGE. (8209, 5855)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (8209 data points).\n",
      "Split on feature emp_length_2 years. (7209, 1000)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (7209 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (1000 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (5855 data points).\n",
      "Split on feature emp_length_10+ years. (3802, 2053)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (3802 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (2053 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 3 (20502 data points).\n",
      "Split on feature home_ownership_MORTGAGE. (10775, 9727)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (10775 data points).\n",
      "Split on feature home_ownership_OTHER. (10741, 34)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (10741 data points).\n",
      "Split on feature emp_length_1 year. (9754, 987)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (9754 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (987 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (34 data points).\n",
      "Split on feature emp_length_10+ years. (27, 7)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (27 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (7 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (9727 data points).\n",
      "Split on feature emp_length_< 1 year. (9186, 541)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (9186 data points).\n",
      "Split on feature emp_length_9 years. (8807, 379)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (8807 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (379 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (541 data points).\n",
      "Split on feature grade_C. (541, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 2 (13101 data points).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on feature home_ownership_MORTGAGE. (5830, 7271)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 3 (5830 data points).\n",
      "Split on feature emp_length_3 years. (5283, 547)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (5283 data points).\n",
      "Split on feature emp_length_1 year. (4705, 578)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (4705 data points).\n",
      "Split on feature emp_length_7 years. (4467, 238)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (4467 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (238 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (578 data points).\n",
      "Split on feature home_ownership_OTHER. (576, 2)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (576 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (2 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (547 data points).\n",
      "Split on feature home_ownership_OTHER. (545, 2)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (545 data points).\n",
      "Split on feature home_ownership_OWN. (468, 77)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (468 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (77 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (2 data points).\n",
      "Split on feature grade_B. (2, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 3 (7271 data points).\n",
      "Split on feature emp_length_2 years. (6702, 569)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (6702 data points).\n",
      "Split on feature emp_length_4 years. (6234, 468)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (6234 data points).\n",
      "Split on feature emp_length_3 years. (5689, 545)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (5689 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (545 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (468 data points).\n",
      "Split on feature grade_B. (468, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (569 data points).\n",
      "Split on feature grade_B. (569, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 0 (73564 data points).\n",
      "Split on feature grade_A. (60204, 13360)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 1 (60204 data points).\n",
      "Split on feature grade_B. (37768, 22436)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 2 (37768 data points).\n",
      "Split on feature grade_C. (19878, 17890)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 3 (19878 data points).\n",
      "Split on feature term_ 36 months. (8812, 11066)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (8812 data points).\n",
      "Split on feature home_ownership_RENT. (5438, 3374)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (5438 data points).\n",
      "Split on feature grade_D. (3299, 2139)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (3299 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (2139 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (3374 data points).\n",
      "Split on feature grade_D. (2198, 1176)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (2198 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (1176 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (11066 data points).\n",
      "Split on feature home_ownership_MORTGAGE. (6987, 4079)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (6987 data points).\n",
      "Split on feature grade_F. (6650, 337)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (6650 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (337 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (4079 data points).\n",
      "Split on feature grade_G. (4003, 76)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (4003 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (76 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 3 (17890 data points).\n",
      "Split on feature term_ 36 months. (3826, 14064)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (3826 data points).\n",
      "Split on feature home_ownership_RENT. (2750, 1076)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (2750 data points).\n",
      "Split on feature emp_length_1 year. (2616, 134)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (2616 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (134 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (1076 data points).\n",
      "Split on feature emp_length_6 years. (1018, 58)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (1018 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (58 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (14064 data points).\n",
      "Split on feature home_ownership_MORTGAGE. (8209, 5855)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (8209 data points).\n",
      "Split on feature emp_length_2 years. (7209, 1000)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (7209 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (1000 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (5855 data points).\n",
      "Split on feature emp_length_10+ years. (3802, 2053)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (3802 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (2053 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 2 (22436 data points).\n",
      "Split on feature term_ 36 months. (1934, 20502)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 3 (1934 data points).\n",
      "Split on feature home_ownership_MORTGAGE. (689, 1245)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (689 data points).\n",
      "Split on feature emp_length_7 years. (647, 42)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (647 data points).\n",
      "Split on feature emp_length_10+ years. (483, 164)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (483 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (164 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (42 data points).\n",
      "Split on feature home_ownership_OWN. (34, 8)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (34 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (8 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (1245 data points).\n",
      "Split on feature emp_length_3 years. (1152, 93)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (1152 data points).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on feature emp_length_7 years. (1081, 71)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (1081 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (71 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (93 data points).\n",
      "Split on feature grade_C. (93, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 3 (20502 data points).\n",
      "Split on feature home_ownership_MORTGAGE. (10775, 9727)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (10775 data points).\n",
      "Split on feature emp_length_1 year. (9785, 990)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (9785 data points).\n",
      "Split on feature home_ownership_OTHER. (9754, 31)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (9754 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (31 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (990 data points).\n",
      "Split on feature home_ownership_OTHER. (987, 3)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (987 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (3 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (9727 data points).\n",
      "Split on feature emp_length_< 1 year. (9186, 541)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (9186 data points).\n",
      "Split on feature emp_length_9 years. (8807, 379)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (8807 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (379 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (541 data points).\n",
      "Split on feature grade_C. (541, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 1 (13360 data points).\n",
      "Split on feature home_ownership_MORTGAGE. (5900, 7460)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 2 (5900 data points).\n",
      "Split on feature term_ 36 months. (70, 5830)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 3 (70 data points).\n",
      "Split on feature home_ownership_OWN. (50, 20)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (50 data points).\n",
      "Split on feature emp_length_4 years. (48, 2)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (48 data points).\n",
      "Split on feature emp_length_7 years. (47, 1)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (47 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (1 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (2 data points).\n",
      "Split on feature grade_B. (2, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (20 data points).\n",
      "Split on feature emp_length_5 years. (17, 3)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (17 data points).\n",
      "Split on feature emp_length_1 year. (15, 2)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (15 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (2 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (3 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 3 (5830 data points).\n",
      "Split on feature emp_length_3 years. (5283, 547)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (5283 data points).\n",
      "Split on feature emp_length_1 year. (4705, 578)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (4705 data points).\n",
      "Split on feature home_ownership_OTHER. (4689, 16)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (4689 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (16 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (578 data points).\n",
      "Split on feature home_ownership_OTHER. (576, 2)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (576 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (2 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (547 data points).\n",
      "Split on feature home_ownership_OTHER. (545, 2)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (545 data points).\n",
      "Split on feature home_ownership_OWN. (468, 77)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (468 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (77 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (2 data points).\n",
      "Split on feature grade_B. (2, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 2 (7460 data points).\n",
      "Split on feature emp_length_2 years. (6879, 581)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 3 (6879 data points).\n",
      "Split on feature emp_length_4 years. (6397, 482)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (6397 data points).\n",
      "Split on feature emp_length_1 year. (6036, 361)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (6036 data points).\n",
      "Split on feature emp_length_3 years. (5475, 561)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (5475 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (561 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (361 data points).\n",
      "Split on feature term_ 36 months. (7, 354)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (7 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (354 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (482 data points).\n",
      "Split on feature term_ 36 months. (14, 468)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (14 data points).\n",
      "Split on feature grade_B. (14, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (468 data points).\n",
      "Split on feature grade_B. (468, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 3 (581 data points).\n",
      "Split on feature term_ 36 months. (12, 569)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (12 data points).\n",
      "Split on feature grade_B. (12, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (569 data points).\n",
      "Split on feature grade_B. (569, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 0 (73564 data points).\n",
      "Split on feature grade_F. (71229, 2335)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 1 (71229 data points).\n",
      "Split on feature grade_A. (57869, 13360)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 2 (57869 data points).\n",
      "Split on feature grade_G. (57232, 637)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 3 (57232 data points).\n",
      "Split on feature grade_E. (51828, 5404)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (51828 data points).\n",
      "Split on feature grade_D. (40326, 11502)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (40326 data points).\n",
      "Split on feature term_ 36 months. (5760, 34566)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (5760 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (34566 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (11502 data points).\n",
      "Split on feature term_ 36 months. (3315, 8187)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (3315 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (8187 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (5404 data points).\n",
      "Split on feature term_ 36 months. (3185, 2219)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (3185 data points).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on feature home_ownership_OTHER. (3184, 1)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (3184 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (1 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (2219 data points).\n",
      "Split on feature emp_length_1 year. (2011, 208)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (2011 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (208 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 3 (637 data points).\n",
      "Split on feature emp_length_3 years. (590, 47)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (590 data points).\n",
      "Split on feature emp_length_2 years. (541, 49)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (541 data points).\n",
      "Split on feature home_ownership_OWN. (495, 46)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (495 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (46 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (49 data points).\n",
      "Split on feature term_ 36 months. (32, 17)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (32 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (17 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (47 data points).\n",
      "Split on feature home_ownership_OTHER. (46, 1)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (46 data points).\n",
      "Split on feature home_ownership_OWN. (44, 2)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (44 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (2 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (1 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 2 (13360 data points).\n",
      "Split on feature term_ 36 months. (259, 13101)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 3 (259 data points).\n",
      "Split on feature emp_length_9 years. (252, 7)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (252 data points).\n",
      "Split on feature home_ownership_RENT. (202, 50)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (202 data points).\n",
      "Split on feature emp_length_8 years. (192, 10)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (192 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (10 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (50 data points).\n",
      "Split on feature emp_length_4 years. (48, 2)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (48 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (2 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (7 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 3 (13101 data points).\n",
      "Split on feature home_ownership_MORTGAGE. (5830, 7271)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (5830 data points).\n",
      "Split on feature emp_length_7 years. (5592, 238)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (5592 data points).\n",
      "Split on feature emp_length_3 years. (5045, 547)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (5045 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (547 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (238 data points).\n",
      "Split on feature home_ownership_OWN. (184, 54)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (184 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (54 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (7271 data points).\n",
      "Split on feature emp_length_2 years. (6702, 569)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (6702 data points).\n",
      "Split on feature emp_length_4 years. (6234, 468)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (6234 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (468 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (569 data points).\n",
      "Split on feature grade_B. (569, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 1 (2335 data points).\n",
      "Split on feature emp_length_7 years. (2197, 138)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 2 (2197 data points).\n",
      "Split on feature term_ 36 months. (1719, 478)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 3 (1719 data points).\n",
      "Split on feature home_ownership_OTHER. (1717, 2)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (1717 data points).\n",
      "Split on feature emp_length_3 years. (1577, 140)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (1577 data points).\n",
      "Split on feature home_ownership_RENT. (904, 673)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (904 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (673 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (140 data points).\n",
      "Split on feature home_ownership_RENT. (73, 67)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (73 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (67 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (2 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 3 (478 data points).\n",
      "Split on feature emp_length_8 years. (460, 18)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (460 data points).\n",
      "Split on feature emp_length_4 years. (433, 27)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (433 data points).\n",
      "Split on feature home_ownership_MORTGAGE. (287, 146)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (287 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (146 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (27 data points).\n",
      "Split on feature home_ownership_OWN. (25, 2)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (25 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (2 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (18 data points).\n",
      "Split on feature home_ownership_OWN. (17, 1)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (17 data points).\n",
      "Split on feature home_ownership_MORTGAGE. (11, 6)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (11 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 6 (6 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (1 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 2 (138 data points).\n",
      "Split on feature term_ 36 months. (109, 29)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 3 (109 data points).\n",
      "Split on feature home_ownership_RENT. (51, 58)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (51 data points).\n",
      "Split on feature home_ownership_MORTGAGE. (8, 43)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (8 data points).\n",
      "Split on feature grade_A. (8, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (43 data points).\n",
      "Split on feature grade_A. (43, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (58 data points).\n",
      "Split on feature grade_A. (58, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 3 (29 data points).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on feature home_ownership_OWN. (25, 4)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (25 data points).\n",
      "Split on feature home_ownership_MORTGAGE. (13, 12)\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (13 data points).\n",
      "Split on feature grade_A. (13, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 5 (12 data points).\n",
      "Split on feature grade_A. (12, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------\n",
      "Subtree, depth = 4 (4 data points).\n",
      "Split on feature grade_A. (4, 0)\n",
      "Creating leaf node.\n",
      "Accuracy Scores: [0.8117366392757376, 0.8122056154802928, 0.8117774198152642]\n",
      "Precision Scores: [0.8128399100388468, 0.8122387390142941, 0.8124897892501225]\n",
      "Recall Scores: [0.9980168193799422, 0.9999497928956947, 0.9987699259445212]\n",
      "F1 Scores: [0.8959603357935657, 0.8963724740087312, 0.8960508090942874]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "my_decision_tree_list = ['gini','information_gain','gain_ratio']\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "for term in my_decision_tree_list:\n",
    "# YOUR CODE HERE\n",
    "    # 构建决策树\n",
    "    my_decision_tree = decision_tree_create(train_data, one_hot_features, target, term, max_depth=6, annotate=False)\n",
    "    # 预测测试集\n",
    "    predictions = predict(my_decision_tree, test_data)\n",
    "    # 计算四项指标\n",
    "    accuracy = accuracy_score(test_data[target], predictions)\n",
    "    precision = precision_score(test_data[target], predictions)\n",
    "    recall = recall_score(test_data[target], predictions)\n",
    "    f1 = f1_score(test_data[target], predictions)\n",
    "    \n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "print(\"Accuracy Scores:\", accuracy_scores)\n",
    "print(\"Precision Scores:\", precision_scores)\n",
    "print(\"Recall Scores:\", recall_scores)\n",
    "print(\"F1 Scores:\", f1_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "树的最大深度为6  \n",
    "\n",
    "###### 双击此处编写\n",
    "\n",
    "划分标准|精度|查准率|查全率|F1\n",
    "-|-|-|-|-\n",
    "信息增益|0.8117366392757376|0.8128399100388468|0.9980168193799422|0.8959603357935657\n",
    "信息增益率|0.8122056154802928|0.8122387390142941|0.9999497928956947|0.8963724740087312\n",
    "基尼指数|0.8117774198152642|0.8124897892501225|0.9987699259445212|0.8960508090942874"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实现决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实验内容：  \n",
    "使用LendingClub Safe Loans数据集：\n",
    "1. 实现信息增益、信息增益率、基尼指数三种划分标准\n",
    "2. 使用给定的训练集完成三种决策树的训练过程\n",
    "3. 计算三种决策树在最大深度为6时测试集上的精度，查准率，查全率，F1值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这部分，我们会实现一个很简单的二叉决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入类库\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入数据\n",
    "loans = pd.read_csv('data/lendingclub/lending-club-data.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对数据进行预处理，将safe_loans作为标记\n",
    "loans['safe_loans'] = loans['bad_loans'].apply(lambda x : +1 if x==0 else -1)\n",
    "del loans['bad_loans']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们只使用grade, term, home_ownership, emp_length这四列作为特征，safe_loans作为标记，只保留loans中的这五列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['grade', 'term','home_ownership','emp_length']\n",
    "target = 'safe_loans'\n",
    "loans = loans[features + [target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 划分训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "loans = shuffle(loans, random_state = 34)\n",
    "split_line = int(len(loans) * 0.6)\n",
    "train_data = loans.iloc[: split_line]\n",
    "test_data = loans.iloc[split_line:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 特征预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(data, features_categorical):\n",
    "    for cat in features_categorical:\n",
    "        one_encoding = pd.get_dummies(data[cat], prefix = cat)\n",
    "        data = pd.concat([data, one_encoding],axis=1)\n",
    "        del data[cat]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = one_hot_encoding(train_data, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取所有特征的名字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "one_hot_features = train_data.columns.tolist()\n",
    "one_hot_features.remove(target)\n",
    "one_hot_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来是对测试集进行one_hot编码，但只要保留出现在one_hot_features中的特征即可·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_tmp = one_hot_encoding(test_data, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个空的DataFrame\n",
    "test_data = pd.DataFrame(columns = train_data.columns)\n",
    "for feature in train_data.columns:\n",
    "    # 如果训练集中当前特征在test_data_tmp中出现了，将其复制到test_data中\n",
    "    if feature in test_data_tmp.columns:\n",
    "        test_data[feature] = test_data_tmp[feature].copy()\n",
    "    else:\n",
    "        # 否则就用全为0的列去替代\n",
    "        test_data[feature] = np.zeros(test_data_tmp.shape[0], dtype = 'uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**处理完后，所有的特征都是0和1，标记是1和-1**，以上就是数据预处理流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 实现3种特征划分准则"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树中有很多常用的特征划分方法，比如信息增益、信息增益率、基尼指数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们需要实现一个函数，它的作用是，给定决策树的某个结点内的所有样本的标记，让它计算出对应划分指标的值是多少"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们会实现上述三种划分指标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**这里我们约定，将所有特征取值为0的样本，划分到左子树，特征取值为1的样本，划分到右子树**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 信息增益"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_entropy(labels_in_node):\n",
    "    '''\n",
    "    求当前结点的信息熵\n",
    "    '''\n",
    "    # 统计样本总个数\n",
    "    num_of_samples = labels_in_node.shape[0]\n",
    "    \n",
    "    if num_of_samples == 0:\n",
    "        return 0\n",
    "    # 统计出标记为1的个数\n",
    "    num_of_positive = len(labels_in_node[labels_in_node == 1])\n",
    "    # 统计出标记为-1的个数\n",
    "    num_of_negative = len(labels_in_node[labels_in_node == -1])             # YOUR CODE HERE\n",
    "    # 统计正例的概率\n",
    "    prob_positive = num_of_positive / num_of_samples\n",
    "    # 统计负例的概率\n",
    "    prob_negative = num_of_negative / num_of_samples                 # YOUR CODE HERE\n",
    "    if prob_positive == 0:\n",
    "        positive_part = 0\n",
    "    else:\n",
    "        positive_part = prob_positive * np.log2(prob_positive)\n",
    "    \n",
    "    if prob_negative == 0:\n",
    "        negative_part = 0\n",
    "    else:\n",
    "        negative_part = prob_negative * np.log2(prob_negative)\n",
    "    \n",
    "    return - ( positive_part + negative_part )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_information_gains(data, features, target, annotate = False):\n",
    "    '''\n",
    "    计算所有特征的信息增益\n",
    "    '''\n",
    "    information_gains = dict()\n",
    "    for feature in features:\n",
    "        left_split_target = data[data[feature] == 0][target]\n",
    "        right_split_target =  data[data[feature] == 1][target]\n",
    "        left_entropy = information_entropy(left_split_target)\n",
    "        left_weight = len(left_split_target) / (len(left_split_target) + len(right_split_target))\n",
    "\n",
    "        # 计算右子树的信息熵\n",
    "        right_entropy = information_entropy(right_split_target)                         # YOUR CODE HERE\n",
    "        # 计算右子树的权重\n",
    "        right_weight = len(right_split_target) / (len(left_split_target) + len(right_split_target))                          # YOUR CODE HERE\n",
    "        # 计算当前结点的信息熵\n",
    "        current_entropy = information_entropy(data[target])\n",
    "        # 计算使用当前特征划分的信息增益\n",
    "        gain = current_entropy - (left_weight * left_entropy + right_weight * right_entropy)                                  # YOUR CODE HERE\n",
    "        # 将特征名与增益值以键值对的形式存储在information_gains中\n",
    "        information_gains[feature] = gain\n",
    "        if annotate:\n",
    "            print(\" \", feature, gain)\n",
    "    return information_gains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 信息增益率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_information_gain_ratios(data, features, target, annotate = False):\n",
    "    '''\n",
    "    计算所有特征的信息增益率并保存起来\n",
    "    '''\n",
    "    gain_ratios = dict()\n",
    "    for feature in features:\n",
    "        left_split_target = data[data[feature] == 0][target]\n",
    "        right_split_target =  data[data[feature] == 1][target]\n",
    "        left_entropy = information_entropy(left_split_target)\n",
    "        \n",
    "        # 计算左子树的权重\n",
    "        left_weight = len(left_split_target) / (len(left_split_target) + len(right_split_target))\n",
    "        # 计算右子树的信息熵\n",
    "        right_entropy = information_entropy(right_split_target)                             # YOUR CODE HERE\n",
    "        # 计算右子树的权重\n",
    "        right_weight = len(right_split_target) / (len(left_split_target) + len(right_split_target))                              # YOUR CODE HERE\n",
    "        # 计算当前结点的信息熵\n",
    "        current_entropy = information_entropy(data[target])\n",
    "        # 计算当前结点的信息增益\n",
    "        gain = current_entropy - (left_weight * left_entropy + right_weight * right_entropy)                                       # YOUR CODE HERE\n",
    "        \n",
    "        if left_weight == 0:\n",
    "            left_IV = 0\n",
    "        else:\n",
    "            left_IV = left_weight * np.log2(left_weight)\n",
    "        \n",
    "        # 计算IV公式中，当前特征为1的值\n",
    "        if right_weight == 0:\n",
    "            right_IV = 0\n",
    "        else:\n",
    "            right_IV = right_weight * np.log2(right_weight)                              # YOUR CODE HERE\n",
    "\n",
    "        IV = - (left_IV + right_IV)\n",
    "        gain_ratio = gain / (IV + np.finfo(np.longdouble).eps)\n",
    "        gain_ratios[feature] = gain_ratio\n",
    "        if annotate:\n",
    "            print(\" \", feature, gain_ratio)\n",
    "            \n",
    "    return gain_ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 基尼指数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(labels_in_node):\n",
    "    '''\n",
    "    计算一个结点内样本的基尼指数\n",
    "    '''\n",
    "    num_of_samples = labels_in_node.shape[0]\n",
    "    if num_of_samples == 0:\n",
    "        return 0\n",
    "    num_of_positive = len(labels_in_node[labels_in_node == 1])\n",
    "    # 统计出-1的个数\n",
    "    num_of_negative = len(labels_in_node[labels_in_node == -1])                    # YOUR CODE HERE\n",
    "    # 统计正例的概率\n",
    "    prob_positive = num_of_positive / num_of_samples\n",
    "    # 统计负例的概率\n",
    "    prob_negative = num_of_negative / num_of_samples                       # YOUR CODE HERE\n",
    "    # 计算基尼值\n",
    "    gini = 1 - prob_positive**2 - prob_negative**2                                # YOUR CODE HERE\n",
    "    \n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gini_indices(data, features, target, annotate = False):\n",
    "    '''\n",
    "    计算使用各个特征进行划分时，各特征的基尼指数\n",
    "    '''\n",
    "    \n",
    "    gini_indices = dict()\n",
    "    for feature in features:\n",
    "        left_split_target = data[data[feature] == 0][target]\n",
    "        right_split_target =  data[data[feature] == 1][target]\n",
    "        left_gini = gini(left_split_target)\n",
    "        \n",
    "        # 计算左子树的权重\n",
    "        left_weight = len(left_split_target) / (len(left_split_target) + len(right_split_target))\n",
    "        # 计算右子树的基尼值\n",
    "        right_gini = gini(right_split_target)                                  # YOUR CODE HERE\n",
    "        # 计算右子树的权重\n",
    "        right_weight = len(right_split_target) / (len(left_split_target) + len(right_split_target))                                # YOUR CODE HERE\n",
    "        # 计算当前结点的基尼指数\n",
    "        gini_index = left_weight * left_gini + right_weight * right_gini                                  # YOUR CODE HERE\n",
    "\n",
    "        gini_indices[feature] = gini_index\n",
    "        \n",
    "        if annotate:\n",
    "            print(\" \", feature, gini_index)\n",
    "            \n",
    "    return gini_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 完成最优特征的选择 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_splitting_feature(data, features, target, criterion = 'gini', annotate = False):\n",
    "    '''\n",
    "    给定划分方法和数据，找到最优的划分特征\n",
    "    \n",
    "    '''\n",
    "    if criterion == 'information_gain':\n",
    "        if annotate:\n",
    "            print('using information gain')\n",
    "        information_gains = compute_information_gains(data, features, target, annotate)\n",
    "        best_feature = max(information_gains.items(), key = lambda x: x[1])[0]\n",
    "        return best_feature\n",
    "\n",
    "    elif criterion == 'gain_ratio':\n",
    "        if annotate:\n",
    "            print('using information gain ratio')\n",
    "        gain_ratios = compute_information_gain_ratios(data, features, target, annotate)\n",
    "        # 根据这些特征和他们的信息增益率，找到最佳的划分特征\n",
    "        best_feature = max(gain_ratios.items(), key=lambda item: item[1])[0]                                                   # YOUR CODE HERE\n",
    "        return best_feature\n",
    "    \n",
    "    elif criterion == 'gini':\n",
    "        if annotate:\n",
    "            print('using gini')\n",
    "        gini_indices = compute_gini_indices(data, features, target, annotate)\n",
    "        # 根据这些特征和他们的基尼指数，找到最佳的划分特征\n",
    "        best_feature = min(gini_indices.items(), key=lambda item: item[1])[0]                                                   # YOUR CODE HERE\n",
    "        return best_feature\n",
    "    else:\n",
    "        raise Exception(\"传入的criterion不合规!\", criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 判断结点内样本的类别是否为同一类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intermediate_node_num_mistakes(labels_in_node):\n",
    "    '''\n",
    "    求树的结点中，样本数少的那个类的样本有多少，比如输入是[1, 1, -1, -1, 1]，返回2\n",
    "    \n",
    "    '''\n",
    "    if len(labels_in_node) == 0:\n",
    "        return 0\n",
    "    # 统计1的个数\n",
    "    num_of_one = len(labels_in_node[labels_in_node == 1])                                    # YOUR CODE HERE\n",
    "    # 统计-1的个数\n",
    "    num_of_minus_one = len(labels_in_node[labels_in_node == -1])                              # YOUR CODE HERE\n",
    "    return num_of_one if num_of_minus_one > num_of_one else num_of_minus_one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 创建叶子结点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_leaf(target_values):\n",
    "    '''\n",
    "    计算出当前叶子结点的标记是什么，并且将叶子结点信息保存在一个dict中\n",
    "    '''\n",
    "    # 创建叶子结点\n",
    "    leaf = {'splitting_feature' : None,'left' : None,'right' : None,'is_leaf': True}\n",
    "    num_ones = len(target_values[target_values == +1])\n",
    "    num_minus_ones = len(target_values[target_values == -1])\n",
    "    if num_ones > num_minus_ones:\n",
    "        leaf['prediction'] = 1\n",
    "    else:\n",
    "        leaf['prediction'] = -1\n",
    "    return leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 递归地创建决策树\n",
    "递归的创建决策树  \n",
    "递归算法终止的三个条件：\n",
    "1. 如果结点内所有的样本的标记都相同，该结点就不需要再继续划分，直接做叶子结点即可\n",
    "2. 如果结点所有的特征都已经在之前使用过了，在当前结点无剩余特征可供划分样本，该结点直接做叶子结点\n",
    "3. 如果当前结点的深度已经达到了我们限制的树的最大深度，直接做叶子结点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**这里需要填写五个部分**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_create(data, features, target, criterion = 'gini', current_depth = 0, max_depth = 10, annotate = False):\n",
    "    if criterion not in ['information_gain', 'gain_ratio', 'gini']:\n",
    "        raise Exception(\"传入的criterion不合规!\", criterion)\n",
    "    remaining_features = features[:]\n",
    "    target_values = data[target]\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Subtree, depth = %s (%s data points).\" % (current_depth, len(target_values)))\n",
    "    if intermediate_node_num_mistakes(target_values) == 0: \n",
    "        print(\"Stopping condition 1 reached.\")\n",
    "        return create_leaf(target_values)\n",
    "    # 如果已经没有剩余的特征可供分割，即remaining_features为空\n",
    "    if len(remaining_features) == 0:                                                                  # YOUR CODE HERE\n",
    "        print(\"Stopping condition 2 reached.\")\n",
    "        return create_leaf(target_values)\n",
    "    # 如果已经到达了我们要求的最大深度，即当前深度达到了最大深度\n",
    "    if current_depth >= max_depth:                                                                 # YOUR CODE HERE\n",
    "        print(\"Reached maximum depth. Stopping for now.\")\n",
    "        return create_leaf(target_values)\n",
    "    splitting_feature = best_splitting_feature(data,features,target,criterion)\n",
    "    # 左子树的数据\n",
    "    left_split = data[data[splitting_feature] == 0]\n",
    "    # 右子树的数据\n",
    "    right_split = data[data[splitting_feature] == 1]                                                    # YOUR CODE HERE\n",
    "    \n",
    "    remaining_features.remove(splitting_feature)\n",
    "    print(\"Split on feature %s. (%s, %s)\" % (\\\n",
    "                      splitting_feature, len(left_split), len(right_split)))\n",
    "    if len(left_split) == len(data):\n",
    "        print(\"Creating leaf node.\")\n",
    "        return create_leaf(left_split[target])\n",
    "    \n",
    "    # 判断右子树是不是“完美”的\n",
    "    if len(right_split) == len(data):\n",
    "        print(\"Creating right node.\")\n",
    "        return create_leaf(right_split[target])                                                      # YOUR CODE HERE\n",
    "\n",
    "    left_tree = decision_tree_create(left_split, remaining_features, target, criterion, current_depth + 1, max_depth, annotate)\n",
    "    right_tree = decision_tree_create(right_split, remaining_features, target, criterion, current_depth + 1, max_depth, annotate)                                                   # YOUR CODE HERE\n",
    "    return {'is_leaf': False,'prediction': None,'splitting_feature': splitting_feature,'left': left_tree,'right': right_tree}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练一个模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_decision_tree = decision_tree_create(train_data, one_hot_features, target, 'gini', max_depth = 6, annotate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，模型就训练好了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们需要完成预测函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(tree, x, annotate = False):\n",
    "    '''\n",
    "    递归的进行预测，一次只能预测一个样本\n",
    "    '''\n",
    "    if tree['is_leaf']:\n",
    "        if annotate:\n",
    "            print (\"At leaf, predicting %s\" % tree['prediction'])\n",
    "        return tree['prediction']\n",
    "    else:\n",
    "        split_feature_value = x[tree['splitting_feature']]\n",
    "        if annotate:\n",
    "             print (\"Split on %s = %s\" % (tree['splitting_feature'], split_feature_value))\n",
    "        if split_feature_value == 0:\n",
    "            return classify(tree['left'], x, annotate)\n",
    "        else:\n",
    "            return classify(tree['right'], x, annotate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们取测试集第一个样本来测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = test_data.iloc[0]\n",
    "print(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('True class: %s ' % (test_sample['safe_loans']))\n",
    "print('Predicted class: %s ' % classify(my_decision_tree, test_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "打印出使用决策树判断的过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(my_decision_tree, test_sample, annotate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 在测试集上对我们的模型进行评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先来编写一个批量预测的函数，传入的是整个测试集那样的pd.DataFrame，这个函数返回一个np.ndarray，存储模型的预测结果  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tree, data):\n",
    "    '''\n",
    "    按行遍历data，对每个样本进行预测，将值存在prediction中，最后返回np.ndarray\n",
    "    '''\n",
    "    predictions = np.zeros(len(data))\n",
    "    for i in range(len(data)):\n",
    "        predictions[i] = classify(tree,data.iloc[i])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 请你计算使用不同评价指标得到模型的四项指标的值，填写在下方表格内\n",
    "**树的最大深度为6**  \n",
    "**这里需要填写一个部分**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "my_decision_tree_list = ['gini','information_gain','gain_ratio']\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "for term in my_decision_tree_list:\n",
    "# YOUR CODE HERE\n",
    "    # 构建决策树\n",
    "    my_decision_tree = decision_tree_create(train_data, one_hot_features, target, term, max_depth=6, annotate=False)\n",
    "    # 预测测试集\n",
    "    predictions = predict(my_decision_tree, test_data)\n",
    "    # 计算四项指标\n",
    "    accuracy = accuracy_score(test_data[target], predictions)\n",
    "    precision = precision_score(test_data[target], predictions)\n",
    "    recall = recall_score(test_data[target], predictions)\n",
    "    f1 = f1_score(test_data[target], predictions)\n",
    "    \n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "print(\"Accuracy Scores:\", accuracy_scores)\n",
    "print(\"Precision Scores:\", precision_scores)\n",
    "print(\"Recall Scores:\", recall_scores)\n",
    "print(\"F1 Scores:\", f1_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "树的最大深度为6  \n",
    "\n",
    "###### 双击此处编写\n",
    "\n",
    "划分标准|精度|查准率|查全率|F1\n",
    "-|-|-|-|-\n",
    "信息增益|0.8117366392757376|0.8128399100388468|0.9980168193799422|0.8959603357935657\n",
    "信息增益率|0.8122056154802928|0.8122387390142941|0.9999497928956947|0.8963724740087312\n",
    "基尼指数|0.8117774198152642|0.8124897892501225|0.9987699259445212|0.8960508090942874"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络：对数几率回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实验内容：\n",
    "\n",
    "使用肿瘤分类数据集\n",
    "1. 完成对数几率回归\n",
    "2. 使用梯度下降求解模型参数\n",
    "3. 绘制模型损失值的变化曲线\n",
    "4. 调整学习率和迭代轮数，观察损失值曲线的变化\n",
    "5. 按照给定的学习率和迭代轮数，初始化新的参数，绘制新模型在训练集和测试集上损失值的变化曲线，完成表格内精度的填写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 导入数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/Breast_Cancer_Wisconsin/data')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.values \n",
    "data_x = data[:,2:-1]\n",
    "data_y = data[:,1:2]\n",
    "data_y = np.reshape(data_y,(-1))\n",
    "\n",
    "data_y[data_y == 'M'] = 0\n",
    "data_y[data_y == 'B'] = 1\n",
    "\n",
    "print(data_x.shape)\n",
    "print(data_y.shape)\n",
    "\n",
    "data_x = data_x.astype(np.float64)\n",
    "data_y = data_y.astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选择40%的数据作为测试集，60%作为训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainX, testX, trainY, testY = train_test_split(data_x, data_y, test_size = 0.4, random_state = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.shape, trainY.shape, testX.shape, testY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "s = StandardScaler()\n",
    "trainX = s.fit_transform(trainX)\n",
    "testX = s.transform(testX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 定义神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 参数初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(m):\n",
    "    '''\n",
    "    初始化参数W和参数b\n",
    "    '''\n",
    "    np.random.seed(32)\n",
    "    W = np.random.normal(size = (m, )) * 0.01\n",
    "    b = np.zeros((1, ))\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 前向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_combination(X, W, b):\n",
    "    '''\n",
    "    完成Z = XW + b的计算\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    Z = np.dot(X, W) + b\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来实现激活函数$\\rm sigmoid$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sigmoid(x):\n",
    "    '''\n",
    "    simgoid 1 / (1 + exp(-x))\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    activations = 1 / (1 + np.exp(-x))\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(X):\n",
    "    return expit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X, W, b):\n",
    "    '''\n",
    "    完成输入矩阵X到最后激活后的预测值y_pred的计算过程\n",
    "    '''\n",
    "    # 求Z\n",
    "    # YOUR CODE HERE\n",
    "    Z = linear_combination(X, W, b)\n",
    "    # 求激活后的预测值\n",
    "    # YOUR CODE HERE\n",
    "    y_pred = my_sigmoid(Z)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logloss(y_true, y_pred):\n",
    "    '''\n",
    "    给定真值y，预测值y_hat，计算对数损失并返回\n",
    "    '''\n",
    "    y_hat = np.clip(y_pred, 1e-10, 1 - 1e-10)\n",
    "    # 求解对数损失\n",
    "    # YOUR CODE HERE\n",
    "    loss = -np.mean(y_true * np.log(y_hat) + (1 - y_true) * np.log(1 - y_hat))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 反向传播"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们接下来要完成损失函数对参数的偏导数的计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(y_true, y_pred, X):\n",
    "    '''\n",
    "    给定预测值y_pred，真值y_true，传入的输入数据X，计算损失函数对参数W的偏导数的导数值dW，以及对b的偏导数的导数值db\n",
    "    '''\n",
    "    # 求损失函数对参数W的偏导数的导数值\n",
    "    # YOUR CODE HERE\n",
    "    dW = np.dot(X.T, y_pred - y_true) / len(y_true)\n",
    "    # 求损失函数对参数b的偏导数的导数值\n",
    "    # YOUR CODE HERE\n",
    "    db = np.mean(y_pred - y_true)\n",
    "    return dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 参数更新\n",
    "给定学习率，结合上一步求出的偏导数，完成梯度下降的更新公式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(W, b, dW, db, learning_rate):\n",
    "    '''\n",
    "    梯度下降，给定参数W，参数b，以及损失函数对他们的偏导数，使用梯度下降更新参数W和参数b\n",
    "    '''\n",
    "    W -= learning_rate * dW\n",
    "    # 对参数b进行更新\n",
    "    # YOUR CODE HERE\n",
    "    b -= learning_rate * db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们来完成整个反向传播和更新参数的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(y_true, y_pred, X, W, b, learning_rate):\n",
    "    '''\n",
    "    反向传播，包含了计算损失函数对各个参数的偏导数的过程，以及梯度下降更新参数的过程\n",
    "    '''\n",
    "    dW, db = compute_gradient(y_true, y_pred, X)\n",
    "    update(W, b, dW, db, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 训练函数的编写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们已经实现了完成训练需要的子函数，接下来就是组装了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainX, trainY, testX, testY, W, b, epochs, learning_rate = 0.01, verbose = False):\n",
    "    '''\n",
    "    训练，我们要迭代epochs次，每次迭代的过程中，做一次前向传播和一次反向传播\n",
    "    同时记录训练集和测试集上的损失值，后面画图\n",
    "    '''\n",
    "    training_loss_list = []\n",
    "    testing_loss_list = []\n",
    "    for i in range(epochs):\n",
    "        # 计算训练集前向传播得到的预测值\n",
    "        # YOUR CODE HERE\n",
    "        train_pred = forward(trainX, W, b)\n",
    "        # 计算当前训练集的损失值\n",
    "        # YOUR CODE HERE\n",
    "        training_loss = logloss(trainY, train_pred)\n",
    "        # 计算测试集前向传播得到的预测值\n",
    "        # YOUR CODE HERE\n",
    "        test_pred = forward(testX, W, b)\n",
    "        # 计算当前测试集的损失值\n",
    "        # YOUR CODE HERE\n",
    "        testing_loss = logloss(testY, test_pred)\n",
    "        if verbose == True:\n",
    "            print('epoch %s, training loss:%s'%(i + 1, training_loss))\n",
    "            print('epoch %s, testing loss:%s'%(i + 1, testing_loss))\n",
    "            print()\n",
    "        training_loss_list.append(training_loss)\n",
    "        testing_loss_list.append(testing_loss)\n",
    "        \n",
    "        # 反向传播更新参数\n",
    "        # YOUR CODE HERE\n",
    "        dW, db = compute_gradient(trainY, train_pred, trainX)\n",
    "        update(W, b, dW, db, learning_rate)\n",
    "\n",
    "    return training_loss_list, testing_loss_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 绘制模型损失值变化曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curve(training_loss_list, testing_loss_list):\n",
    "    '''\n",
    "    绘制损失值变化曲线\n",
    "    '''\n",
    "    plt.figure(figsize = (10, 6))\n",
    "    plt.plot(training_loss_list, label = 'training loss')\n",
    "    plt.plot(testing_loss_list, label = 'testing loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, W, b):\n",
    "    '''\n",
    "    预测，调用forward函数完成神经网络对输入X的计算，然后完成类别的划分，大于0.5的变为1，小于等于0.5的变为0\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    y_pred = forward(X, W, b)\n",
    "    prediction = (y_pred > 0.5).astype(int)    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 训练一个神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们的学习率是0.01，迭代200轮"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W, b = initialize(trainX.shape[1])\n",
    "training_loss_list, testing_loss_list = train(trainX, trainY, testX, testY, W, b, 200, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算测试集精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predict(testX, W, b)\n",
    "accuracy_score(testY, prediction)  # 0.9649122807017544"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "绘制损失值变化曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curve(training_loss_list, testing_loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test：初始化新的参数，学习率和迭代轮数按下表设置，绘制其训练集和测试集损失值的变化曲线，完成表格内精度的填写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 双击此处填写\n",
    "\n",
    "学习率|迭代轮数|测试集精度\n",
    "-|-|-\n",
    "0.0001|200|0.8859649122807017\n",
    "0.1|1000|0.9736842105263158"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "W, b = initialize(trainX.shape[1])\n",
    "training_loss_list, testing_loss_list = train(trainX, trainY, testX, testY, W, b, 200, 0.0001)\n",
    "prediction = predict(testX, W, b)\n",
    "print(accuracy_score(testY, prediction))\n",
    "plot_loss_curve(training_loss_list, testing_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "W, b = initialize(trainX.shape[1])\n",
    "training_loss_list, testing_loss_list = train(trainX, trainY, testX, testY, W, b, 200, 0.1)\n",
    "prediction = predict(testX, W, b)\n",
    "print(accuracy_score(testY, prediction))\n",
    "plot_loss_curve(training_loss_list, testing_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "57a9c87e9a70bfc756f51474cb13bba73a6f014493757c6865d8755804382445"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

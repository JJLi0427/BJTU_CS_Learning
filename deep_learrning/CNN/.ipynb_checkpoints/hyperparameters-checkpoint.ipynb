{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e36ace1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  \n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np  \n",
    "import random  \n",
    "from matplotlib import pyplot as plt  \n",
    "import os  \n",
    "import shutil\n",
    "import torch.nn as nn \n",
    "import time  \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 启用CUDA加速"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da4500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(acc1, acc2, loss1, loss2):\n",
    "    x = range(len(acc1))\n",
    "    # 创建一个1行2列的图像布局\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    # 画图函数\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc1, label=\"train\")\n",
    "    plt.plot(x, acc2, color='r', label=\"test\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"acc\")\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss1, label=\"train\")\n",
    "    plt.plot(x, loss2, color='r', label=\"test\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fd5c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset(folders):\n",
    "    for folder in folders:\n",
    "        for filename in os.listdir(folder):\n",
    "            filepath = os.path.join(folder, filename)\n",
    "            if os.path.isfile(filepath) or os.path.islink(filepath):\n",
    "                os.unlink(filepath)\n",
    "            elif os.path.isdir(filepath):\n",
    "                shutil.rmtree(filepath)\n",
    "\n",
    "# 重置训练集和测试集\n",
    "folders = ['./cardata/train/car', \n",
    "           './cardata/train/bus', \n",
    "           './cardata/train/truck',\n",
    "           './cardata/test/car', \n",
    "           './cardata/test/bus', \n",
    "           './cardata/test/truck']\n",
    "\n",
    "# 划分数据集函数\n",
    "def makedata():\n",
    "    random.seed(0)\n",
    "    datapath = os.path.join(os.getcwd(), \"cardata\")\n",
    "    traindata = os.path.join(datapath, \"train\")\n",
    "    testdata = os.path.join(datapath, \"test\")\n",
    "    types = ['car', 'bus', 'truck']\n",
    "    for t in types:\n",
    "        tpath = os.path.join(datapath, t)\n",
    "        images = os.listdir(tpath)\n",
    "        num = len(images)\n",
    "        testimg = random.sample(images, k=int(num * 0.25)) # 25%做测试集\n",
    "        for _, img in enumerate(images):\n",
    "            if img in testimg:\n",
    "                # 制作测试集\n",
    "                imgpath = os.path.join(tpath, img)\n",
    "                topath = os.path.join(testdata, t)\n",
    "                shutil.copy(imgpath, topath)\n",
    "            else:\n",
    "                # 制作训练集\n",
    "                imgpath = os.path.join(tpath, img)\n",
    "                topath = os.path.join(traindata, t)\n",
    "                shutil.copy(imgpath, topath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f6d138",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset(folders)\n",
    "makedata()\n",
    "data_transform = {\"train\": transforms.Compose([transforms.Resize((64 ,64)), # 拉伸到统一大小\n",
    "                            transforms.RandomHorizontalFlip(),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))]),\n",
    "                  \"test\": transforms.Compose([transforms.Resize((64, 64)),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))])}\n",
    "\n",
    "batch_size = 128\n",
    "train_dataset = torchvision.datasets.ImageFolder(root = os.path.join(os.getcwd(), \"cardata/train\"), transform = data_transform[\"train\"])\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle = True, num_workers = 8)\n",
    "test_dataset = torchvision.datasets.ImageFolder(root = os.path.join(os.getcwd(), \"cardata/test\"), transform = data_transform[\"test\"])\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size, shuffle=False, num_workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c242f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, inchannel, outchannel, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        # 正常卷积部分，堆叠了两层卷积\n",
    "        self.left = nn.Sequential(\n",
    "            nn.Conv2d(inchannel, outchannel, \n",
    "                      kernel_size=3, stride=stride,\n",
    "                      padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(outchannel, outchannel, \n",
    "                      kernel_size=3, stride=1, \n",
    "                      padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.left(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb880678",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, ResidualBlock):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inchannel = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.layer1 = self.make_layer(ResidualBlock, 64,  2, stride=1)\n",
    "        self.layer2 = self.make_layer(ResidualBlock, 128, 2, stride=2)\n",
    "        self.layer3 = self.make_layer(ResidualBlock, 256, 2, stride=2)\n",
    "        self.layer4 = self.make_layer(ResidualBlock, 512, 2, stride=2)\n",
    "        self.fc = nn.Linear(512, 3)\n",
    "\n",
    "    def make_layer(self, block, channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)   #strides=[1,1]\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.inchannel, channels, stride))\n",
    "            self.inchannel = channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = nn.functional.avg_pool2d(out, 8)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afadaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(net, data_loader, device):\n",
    "    net.train()\n",
    "    train_batch_num = len(data_loader)\n",
    "    total_loss = 0 \n",
    "    correct = 0 \n",
    "    sample_num = 0\n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        data = data.to(device).float()\n",
    "        target = target.to(device).long()\n",
    "        optimizer.zero_grad()\n",
    "        output = net(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        prediction = torch.argmax(output, 1)\n",
    "        correct += (prediction == target).sum().item()\n",
    "        sample_num += len(prediction)\n",
    "    loss = total_loss / train_batch_num\n",
    "    acc = correct / sample_num\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84f715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(net, data_loader, device):\n",
    "    net.eval() \n",
    "    test_batch_num = len(data_loader)\n",
    "    total_loss = 0\n",
    "    correct = 0  \n",
    "    sample_num = 0\n",
    "    # 不进行梯度变化\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(data_loader):\n",
    "            data = data.to(device).float()\n",
    "            target = target.to(device).long()\n",
    "            output = net(data)\n",
    "            loss = criterion(output, target)\n",
    "            total_loss += loss.item()\n",
    "            prediction = torch.argmax(output, 1)\n",
    "            correct += (prediction == target).sum().item()\n",
    "            sample_num += len(prediction)\n",
    "    loss = total_loss / test_batch_num\n",
    "    acc = correct / sample_num\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d894517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型初始化\n",
    "lr = 0.01\n",
    "epochs = 30\n",
    "net = ResNet(ResidualBlock).to(device)\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.Adam(net.parameters(),lr = lr)   \n",
    "\n",
    "# 存储每一个epoch的loss与acc的变化，便于后面可视化\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_loss_list = []\n",
    "test_acc_list = []\n",
    "timestart = time.time()\n",
    "# 进行训练\n",
    "for epoch in range(epochs):\n",
    "    print('Epoch %d: '%(epoch+1), end=\"\")\n",
    "    train_loss, train_acc = train_epoch(net, train_loader, device)\n",
    "    print('train: loss %.6f acc %.6f; '%(train_loss, train_acc), end=\"\")\n",
    "    test_loss, test_acc = test_epoch(net, test_loader, device)\n",
    "    print('test: loss %.6f, acc %.6f'%(test_loss, test_acc))\n",
    "    # 保存各个指标\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_acc_list.append(train_acc)\n",
    "    test_loss_list.append(test_loss)\n",
    "    test_acc_list.append(test_acc)\n",
    "spendtime = (time.time() - timestart)  \n",
    "print('Spend time: %.3f'%(spendtime))\n",
    "draw(train_acc_list, test_acc_list, train_loss_list, test_loss_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
